{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> ILI285 - Computación Científica I / INF285 - Computación Científica</h1>\n",
    "    <h1> Tarea 3:  </h1>\n",
    "    <h3> [S]cientific [C]omputing [T]eam 2019</h3>\n",
    "</center>\n",
    "<p>\n",
    "<center>Junio 2019 - v2.0 </center>\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "Hasta hace no más de una década, los dibujos animados y videojuegos eran visualizados con un *framerate* de entre 12 a 24 *frames* por segundo (*FPS*). Sin embargo, las mejoras en las tecnologías nos permiten hoy disfrutar de videos con una mucho mejor fluidez, siendo el *framerate* estándar actual de 60 *FPS*.\n",
    "\n",
    "### ¿Qué es Interpolación de Movimiento o *Motion-Compensated Frame Interpolation* (MCFI)? \n",
    "\n",
    "Corresponde a un método de **procesamiento de video** en el cual se generan *frames* de animación entre los *frames* existentes, utilizando métodos de interpolación. El objetivo principal es mejorar la fluidez del video.\n",
    "\n",
    "En esta tarea implementaremos MCFI aplicando los algoritmos de interpolación aprendidos en la clase de Computación Científica, para mejorar el *framerate* de un video que posee $N$ FPS (*Frames Per Second*), para luego generar un nuevo video con un total de *frames* mayor al original.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VirQAbpPC_Hf"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "#pip3 install imutils\n",
    "import imutils\n",
    "#pip3 install opencv-python\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as scp\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "El problema, descrito de forma general, corresponde al incremento de los FPS de un video, esperando mejorar la fluidez de este. Junto a esta tarea, se adjuntan cuatro videos. El nombre de cada video sigue el formato `video_Nfps.mp4` [1], donde $N$ indica la cantidad de FPS del video. Para esta tarea, trabajaremos con videos con 60, 30, 15 y 5 FPS. Una vez incrementados los FPS, compararemos los resultados con la versión *original* del video.\n",
    "\n",
    "Para ilustrar de manera inicial lo que se desea realizar, considere un video compuesto por los 2 siguientes *frames*:\n",
    "\n",
    "<img src=\"interpolacion2.png\" style=\"float:center;height:200px\">\n",
    "\n",
    "Su algoritmo de interpolación debe ser capaz de construir una o más funciones, utilizando como *data* los frames disponibles del video. En este ejemplo, podríamos construir una interpolación utilizando como datos los dos *frames* disponibles y, mediante esta función, se pueden generar uno o más *frames* dentro de la secuencia para aumentar el *framerate* de su video:\n",
    "\n",
    "<img src=\"interpolacion3.png\" style=\"float:center;height:198px\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 1 (40 puntos). Testing de métodos de interpolación\n",
    "\n",
    "En esta pregunta implementaremos una forma sencilla de interpolación de videos. Considere que el video contiene un total de $M$ frames.\n",
    "\n",
    "El proceso de interpolación será **a través de cada pixel**, es decir, si se desea interpolar el pixel $(i, j)$ y generar un nuevo frame, entonces el interpolador se debe construir utilizando como *data* todos los pixeles $(i, j)$ del video. De una forma más matemática, el conjunto de datos está definido por:\n",
    "\n",
    "$$\n",
    "    S_{i,j} = \\{ (x_1, I_1[i, j]), (x_2, I_2[i,j]), \\dots, (x_M, I_M[i,j]) \\},\n",
    "$$\n",
    "\n",
    "donde $x_i$ corresponde a un punto siguiendo una distribución equiespaciada o de Chebyshev e $I_k[i,j]$ denota el valor del pixel $(i,j)$ del $k$-ésimo frame. Su labor en esta pregunta es interpolar los datos de $S_{i,j}$ y así construir los pixeles que se desean agregar entre cada par de frames.\n",
    "\n",
    "1. Implemente la función _interpolate_\\__frames (frames, dst_\\__fps, seconds, interpolator)_. Esta función recibe como parámetros:\n",
    "    * La matriz de _frames_: Video original a interpolar.\n",
    "    * La cantidad original de *fps*.\n",
    "    * La cantidad de _fps_ deseados (mayor a los _fps_ originales).\n",
    "    * La cantidad de segundos que tendrá el video.\n",
    "    * Un string _interpolator_, cuyos valores posibles son:\n",
    "        * \"spline-cubica\": Spline cúbica. Estudie y seleccione un tipo de condición de borde adecuado para el problema, justificando su elección.\n",
    "        * \"spline-lineal\": Spline lineal.\n",
    "        * \"lagrange\": Interpolación polinomial mediante el método Interpolación de Lagrange.\n",
    "        * \"baricentrica\": Interpolación Baricéntrica [2].\n",
    "    * Un string 'points_type', cuyos valores posibles son:\n",
    "        * \"equi\": Para usar una distribución equiespaciada de puntos en el eje de las abscisas.\n",
    "        * \"cheb\": Los x_i (o eje de las abscisas) son los puntos de Chebyshev.\n",
    "\n",
    "    En caso de utilizar código ajeno, ya sean librerías, notebooks del curso u otro, recuerde referenciar apropiadamente.<br/><br/>\n",
    "\n",
    "2. Mediante la función implementada anteriormente, aumentaremos los *framerates* de los videos disponibles. Para esto:\n",
    "    * Tomando como base el _video_\\__30fps.mp4_, genere un video de 60 fps.\n",
    "    * Tomando como base el _video_\\__15fps.mp4_, genere un video de 30 fps.\n",
    "    * Tomando como base el _video_\\__5fps.mp4_, genere un video de 15 fps.\n",
    "    * Tomando como base el _video_\\__5fps.mp4_, genere un video de 60 fps.\n",
    "\n",
    "    Para esto, utilize los 4 interpoladores generados y las distribuciones de puntos especificadas. Mida los tiempos de cómputos de cada método, con cada distribución de puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chebyshev_points(xmin,xmax,n):\n",
    "    ns = np.arange(1,n+1)\n",
    "    x = np.cos((2*ns-1)*np.pi/(2*n))\n",
    "    y = np.sin((2*ns-1)*np.pi/(2*n))\n",
    "    return (xmin+xmax)/2 + (xmax-xmin)*x/2\n",
    "\n",
    "def matrix_to_video(frames, old_fps, new_fps, width, height, interpolator, points_type):\n",
    "    name = \"video_\"+str(old_fps)+\"_to_\"+str(new_fps)+\"fps_\"+interpolator+\"_\"+points_type+\".mp4\"\n",
    "    out = cv2.VideoWriter(name, cv2.VideoWriter_fourcc('m','p','4','v'), new_fps, (width,height))\n",
    "    \n",
    "    for i in range(frames.shape[2]):\n",
    "        frame = np.uint8(frames[:,:,i])\n",
    "        out.write(np.dstack([frame, frame, frame]))\n",
    "    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "frames: array of frames (height x width x total_frames)\n",
    "old_fps: Number of fps of the original video\n",
    "new_fps: fps of output matrix \n",
    "seconds: seconds of video \n",
    "interpolator: Interpolator type\n",
    "points_type: Points distribution to use\n",
    "\n",
    "return: dst_frames (array of frames (height x width x dst_fps*seconds))\n",
    "'''\n",
    "\n",
    "def interpolate_frames(frames, old_fps, new_fps, seconds, interpolator, points_type):            \n",
    "    \n",
    "    if(new_fps > old_fps):\n",
    "        start_time = time() \n",
    "        mult = new_fps/old_fps\n",
    "        height = frames.shape[0]\n",
    "        width = frames.shape[1]\n",
    "        dst_frames = np.zeros((height, width, round(new_fps)*seconds), dtype=np.uint8)\n",
    "        \n",
    "        if(points_type == \"equi\"):\n",
    "            x = np.arange(0, frames.shape[2], 1)\n",
    "            xs = np.linspace(0, frames.shape[2]-1, num=round(new_fps)*seconds)\n",
    "            \n",
    "        elif(points_type == \"cheb\"):\n",
    "            x = Chebyshev_points(old_fps, 1, old_fps*seconds)\n",
    "            xs = Chebyshev_points(old_fps, 1, new_fps*seconds)\n",
    "            \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                ys = frames[i, j] \n",
    "\n",
    "                if(interpolator == \"spline-cubica\"): \n",
    "                    S = scp.CubicSpline(x, ys)\n",
    "\n",
    "                elif(interpolator == \"spline-lineal\"):\n",
    "                    S = scp.UnivariateSpline(x, ys)\n",
    "\n",
    "                elif(interpolator == \"lagrange\"):\n",
    "                    S = scp.lagrange(x, ys)\n",
    "\n",
    "                elif(interpolator == \"baricentrica\"):\n",
    "                    S = scp.BarycentricInterpolator(x, ys)\n",
    "\n",
    "                else:\n",
    "                    break  \n",
    "\n",
    "                dst_frames[i][j] = S(xs)\n",
    "\n",
    "        fps = int(dst_frames.shape[2]/seconds)\n",
    "        matrix_to_video(dst_frames, old_fps, fps, width, height, interpolator, points_type)\n",
    "        end_time = time() \n",
    "        exe_time = end_time - start_time\n",
    "        print(\"Video \" + str(old_fps) + \"-\" + str(new_fps) + \"fps (\" + interpolator + \"): \" + str(exe_time) +\" segs.\")\n",
    "            \n",
    "    return dst_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el manejo del video en el *notebook*, se les facilita la función `video_to_matrix` que les permitirá abrir un video y transformarlo a una estructura de datos de *numpy*. El resultado será una *array* de dimensión $\\text{height}\\times\\text{width}\\times\\text{Total de frames}$, donde *height* corresponde a la altura (en pixeles) del video y *width* al ancho del video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Carga de video a matriz de [height, width, fps*seconds], dejando en escala de grises cada frame, \n",
    "reduciendo su dimensionalidad.\n",
    "\n",
    "Input:\n",
    "    src_name: nombre (o path) de video de origen\n",
    "    seconds: cantidad de tiempo en segundos a considerar del video de origen.\n",
    "\n",
    "Output: \n",
    "    frames: matriz de shape [height, width, fps*seconds], la cual contiene los frames del video original\n",
    "    number_fps: frames por segundo del video original\n",
    "'''\n",
    "def video_to_matrix(src_name, seconds):\n",
    "    # Se lee el video\n",
    "    stream = cv2.VideoCapture(src_name)\n",
    "    \n",
    "    # Dimension del video y fps\n",
    "    height = round(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = round(stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    number_fps = stream.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    frames = np.zeros((height, width, round(number_fps)*seconds), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(round(number_fps)*seconds):\n",
    "        # Leer el video hasta que no hayan más datos\n",
    "        (grabbed, frame) = stream.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "            \n",
    "        # Leer el frame y cambiarlo a escala de grises\n",
    "        frame = cv2.resize(frame, (width, height)) \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames[:,:,i] = frame\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, el siguiente código sirve para visualizar un video dentro del mismo *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('\\\n",
    "<div align=\"middle\">\\\n",
    "<video width=\"80%\" controls>\\\n",
    "      <source src=\"./{0}\" type=\"video/mp4\">\\\n",
    "</video></div>'.format('video_60fps.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 5-15fps (spline-cubica): 105.99678826332092 segs.\n",
      "Video 5-15fps (spline-cubica): 90.10140657424927 segs.\n",
      "Video 5-60fps (spline-cubica): 107.00946283340454 segs.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5e524548af5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'video_5fps.mp4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0minterpolate_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtipo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"equi\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0minterpolate_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtipo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cheb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#15 a 30 fps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-326e4bc77a37>\u001b[0m in \u001b[0;36minterpolate_frames\u001b[1;34m(frames, old_fps, new_fps, seconds, interpolator, points_type)\u001b[0m\n\u001b[0;32m     46\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0mdst_frames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst_frames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tipos = [\"spline-cubica\", \"spline-lineal\", \"baricentrica\"]    \n",
    "#tipos = [\"lagrange\"]\n",
    "\n",
    "for tipo in tipos:\n",
    "    \n",
    "    #5 a 15 fps\n",
    "    frames = video_to_matrix('video_5fps.mp4', 5)\n",
    "    interpolate_frames(frames, 5, 15, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 5, 15, 5, tipo, \"cheb\")\n",
    "    \n",
    "    #5 a 60 fps\n",
    "    frames = video_to_matrix('video_5fps.mp4', 5)\n",
    "    interpolate_frames(frames, 5, 60, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 5, 60, 5, tipo, \"cheb\")\n",
    "    \n",
    "    #15 a 30 fps\n",
    "    frames = video_to_matrix('video_15fps.mp4', 5)\n",
    "    interpolate_frames(frames, 15, 30, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 15, 30, 5, tipo, \"cheb\")\n",
    "    \n",
    "    #30 a 60 fps\n",
    "    frames = video_to_matrix('video_30fps.mp4', 5)\n",
    "    interpolate_frames(frames, 30, 60, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 30, 60, 5, tipo, \"cheb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 (15 puntos). Visualización del interpolador y del error, a través del tiempo\n",
    "\n",
    "1. Utilizando el *widget* adjunto, visualice los resultados generados por los interpoladores, su error y comente al respecto. ¿Qué método le parece que tiene un mejor desempeño?\n",
    "\n",
    "**Nota**: usted debe modificar el *widget* en las secciones necesarias para que lea correctamente los videos generados por usted, acorde a los parámetros que se pueden variar. Puede modificar secciones del *widget* para que se adapte a sus códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget to plot the interpolation function\n",
    "def plot_interpolation(method, points_dist, i, j, fps_increase_type):\n",
    "    \n",
    "    # Elegimos el video a trabajar\n",
    "    if fps_increase_type == \"5->15\":\n",
    "        frames = video_to_matrix('video_15fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_5_to_15.mp4' # Acá va el video de 15 fps que generó a partir del de 5 fps\n",
    "    elif fps_increase_type == \"5->60\":\n",
    "        frames = video_to_matrix('video_60fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_5_to_60.mp4' # Acá va el video de 60 fps que generó a partir del de 5 fps\n",
    "    elif fps_increase_type == \"15->30\":\n",
    "        frames = video_to_matrix('video_30fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_15_to_30.mp4' # Acá va el video de 30 fps que generó a partir del de 15 fps\n",
    "    else:\n",
    "        frames = video_to_matrix('video_60fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_30_to_60.mp4' # Acá va el video de 60 fps que generó a partir del de 30 fps\n",
    "        \n",
    "    # Un punto por frame\n",
    "    x = np.arange(0, frames.shape[2], 1)\n",
    "    \n",
    "    # Usar el interpolador acá (Matrix aleatoria es simplemente como un ejemplo para introducir ruido)\n",
    "    interp_frames = video_to_matrix(interpolated_video_name, 5) + np.random.rand(frames.shape[0], frames.shape[1], frames.shape[2])\n",
    "    \n",
    "    plt.figure(figsize=(15, 14))\n",
    "    \n",
    "    # Grafico del interpolador y los pixeles reales\n",
    "    plt.subplot(211)\n",
    "    plt.plot(x, interp_frames[i,j,:], 'rx-', label='Video interpolados')\n",
    "    plt.plot(x, frames[i,j,:], 'bd', label='Video esperado')\n",
    "    plt.ylim([0, 256])\n",
    "    plt.title('Comparación entre los pixeles interpolados y los deseados')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Valor pixel')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Grafico del error\n",
    "    plt.subplot(212)\n",
    "    error_matrix = frames - interp_frames\n",
    "    plt.plot(x, error_matrix[i,j,:], 'sk-', label='Error de interpolación')\n",
    "    mean_error = np.zeros(error_matrix.shape[2])\n",
    "    sigma = mean_error.copy()\n",
    "    for k in range(error_matrix.shape[2]):\n",
    "        mean_error[k] = error_matrix[:,:,k].mean()\n",
    "        sigma[k] = error_matrix[:,:,k].std()\n",
    "    plt.plot(x, mean_error, '.-', label='Error medio de interpolación')\n",
    "    plt.plot(x, mean_error + sigma, label='Error medio + desviación estándar')\n",
    "    plt.plot(x, mean_error - sigma, label='Error medio - desviación estándar')\n",
    "    plt.title('Error de interpolación')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Error')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    plot_interpolation, \n",
    "    method=[\"spline-cubica\",\"spline-lineal\",\"lagrange\",\"baricentrica\"],\n",
    "    points_dist=[\"equi\",\"cheb\"],\n",
    "    j=(0, 511),\n",
    "    i=(0, 269),\n",
    "    fps_increase_type=[\"5->60\", \"5->15\", \"15->30\", \"30->60\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 (25 puntos). Comparación de Videos\n",
    "\n",
    "1. Utilizando los videos generados en la pregunta anterior, compare visualmente los videos generados con su versión de \"origen\" (video original al que se le agregaron nuevos *frames*) y con la versión \"esperada\" del video; por ejemplo, para la interpolación de 15fps a 30fps, el video de origen sería _video_\\__15fps.mp4_, y el video esperado _video_\\__30fps.mp4_. Comente al respecto. ¿Se realiza correctamente la interpolación? ¿Qué es lo que está haciendo visualmente la interpolación en los videos?\n",
    "\n",
    "    Para ayudar a la visualización de los videos, puede hacer uso de la función _concat_\\__2_\\__videos (src_\\__name, dst_\\__name, seconds)_, la cual permite concatenar o \"unir\" dos videos con el mismo framerate para realizar una comparativa en un nuevo video generado.\n",
    "\n",
    "    _NOTA: Debe hacer un preprocesamiento sobre el video de origen para compararlo con la interpolación, pues la función solo permite unir 2 videos de igual framerate. Una solución simple es repetir cada frame la cantidad necesaria para completar el framerate deseado_ <br/><br/>\n",
    "\n",
    "2. Comente respecto a los tiempos de cómputo obtenidos. ¿Existe alguna correlación entre la calidad del video generado y los tiempos de cómputo?\n",
    "\n",
    "3. Comente respecto al efecto de la distribución de puntos. ¿Genera alguna diferencia la distribución de puntos equiespaciada respecto a los puntos de Chebyshev?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "src_name: name/path of first video\n",
    "dst_name: name/path of second video\n",
    "seconds : seconds of video to consider.\n",
    "\n",
    "returns: None\n",
    "'''\n",
    "\n",
    "def concat_2_videos(src_name, dst_name, seconds):\n",
    "    stream = cv2.VideoCapture(src_name)\n",
    "    src_frames = video_to_matrix(src_name, seconds)\n",
    "    print(\"FPS VIDEO \"+src_name+\": \",int(src_frames.shape[2]/seconds))\n",
    "    \n",
    "    stream_2 = cv2.VideoCapture(dst_name)  \n",
    "    dst_frames = video_to_matrix(dst_name, seconds)\n",
    "    print(\"FPS VIDEO \"+dst_name+\": \",int(dst_frames.shape[2]/seconds))\n",
    "\n",
    "    # Close original videos\n",
    "    stream.release()\n",
    "    stream_2.release()\n",
    "    \n",
    "    if dst_frames.shape[2] != src_frames.shape[2]:\n",
    "        print(\"No es posible concatenar dos videos de distinto fps\")\n",
    "        return\n",
    "    \n",
    "    fps = int(dst_frames.shape[2]/seconds)\n",
    "    \n",
    "    #concatenate both videos\n",
    "    conc_frames = np.concatenate((src_frames, dst_frames), axis=1)\n",
    "    \n",
    "    height = conc_frames.shape[0]\n",
    "    width = conc_frames.shape[1]\n",
    "    \n",
    "    #saving comparison on a new video\n",
    "    out = cv2.VideoWriter(\"comparison_\"+src_name+\"_vs_\"+dst_name,cv2.VideoWriter_fourcc('m','p','4','v'), fps, (width,height))\n",
    "   \n",
    "    for i in range(conc_frames.shape[2]):\n",
    "        frame = np.uint8(conc_frames[:,:,i])\n",
    "        out.write(np.dstack([frame, frame, frame]))\n",
    "    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 4 (10 puntos): Conclusión\n",
    "\n",
    "Considerando todo el trabajo anterior, concluya al respecto.\n",
    "\n",
    "1. _¿En palabras simples, qué es lo que realiza el interpolador entre cada par de *frames*?. **Hint: Un análisis frame a frame puede ayudar a responder esto.**_\n",
    "\n",
    "2. _¿De qué manera se pueden mejorar los métodos estudiados para aumentar el framerate de un video?. **Hint: ¿Es adecuado considerar el conjunto de pixeles como independientes entre sí?**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "[1] Stock footage provided by Videvo, downloaded from https://www.videvo.net\n",
    "\n",
    "[2] Barycentric Lagrange Interpolation, https://people.maths.ox.ac.uk/trefethen/barycentric.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea3_borrador.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/sgallard/tareasCC/blob/master/tarea3/Tarea3_borrador.ipynb",
     "timestamp": 1558739969669
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
