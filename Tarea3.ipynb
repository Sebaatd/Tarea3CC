{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> ILI285 - Computación Científica I / INF285 - Computación Científica</h1>\n",
    "    <h1> Tarea 3: Interpolación  </h1>\n",
    "    <h3> Sebastián Torrico - sebastian.torrico.12@sansano.usm.cl - 201330061-8</h3>\n",
    "    <h3> [S]cientific [C]omputing [T]eam 2019</h3>\n",
    "</center>\n",
    "<p>\n",
    "<center>Junio 2019 - v2.0 </center>\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "Hasta hace no más de una década, los dibujos animados y videojuegos eran visualizados con un *framerate* de entre 12 a 24 *frames* por segundo (*FPS*). Sin embargo, las mejoras en las tecnologías nos permiten hoy disfrutar de videos con una mucho mejor fluidez, siendo el *framerate* estándar actual de 60 *FPS*.\n",
    "\n",
    "### ¿Qué es Interpolación de Movimiento o *Motion-Compensated Frame Interpolation* (MCFI)? \n",
    "\n",
    "Corresponde a un método de **procesamiento de video** en el cual se generan *frames* de animación entre los *frames* existentes, utilizando métodos de interpolación. El objetivo principal es mejorar la fluidez del video.\n",
    "\n",
    "En esta tarea implementaremos MCFI aplicando los algoritmos de interpolación aprendidos en la clase de Computación Científica, para mejorar el *framerate* de un video que posee $N$ FPS (*Frames Per Second*), para luego generar un nuevo video con un total de *frames* mayor al original.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VirQAbpPC_Hf"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "#pip3 install imutils\n",
    "import imutils\n",
    "#pip3 install opencv-python\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as scp\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "El problema, descrito de forma general, corresponde al incremento de los FPS de un video, esperando mejorar la fluidez de este. Junto a esta tarea, se adjuntan cuatro videos. El nombre de cada video sigue el formato `video_Nfps.mp4` [1], donde $N$ indica la cantidad de FPS del video. Para esta tarea, trabajaremos con videos con 60, 30, 15 y 5 FPS. Una vez incrementados los FPS, compararemos los resultados con la versión *original* del video.\n",
    "\n",
    "Para ilustrar de manera inicial lo que se desea realizar, considere un video compuesto por los 2 siguientes *frames*:\n",
    "\n",
    "<img src=\"interpolacion2.png\" style=\"float:center;height:200px\">\n",
    "\n",
    "Su algoritmo de interpolación debe ser capaz de construir una o más funciones, utilizando como *data* los frames disponibles del video. En este ejemplo, podríamos construir una interpolación utilizando como datos los dos *frames* disponibles y, mediante esta función, se pueden generar uno o más *frames* dentro de la secuencia para aumentar el *framerate* de su video:\n",
    "\n",
    "<img src=\"interpolacion3.png\" style=\"float:center;height:198px\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 1 (40 puntos). Testing de métodos de interpolación\n",
    "\n",
    "En esta pregunta implementaremos una forma sencilla de interpolación de videos. Considere que el video contiene un total de $M$ frames.\n",
    "\n",
    "El proceso de interpolación será **a través de cada pixel**, es decir, si se desea interpolar el pixel $(i, j)$ y generar un nuevo frame, entonces el interpolador se debe construir utilizando como *data* todos los pixeles $(i, j)$ del video. De una forma más matemática, el conjunto de datos está definido por:\n",
    "\n",
    "$$\n",
    "    S_{i,j} = \\{ (x_1, I_1[i, j]), (x_2, I_2[i,j]), \\dots, (x_M, I_M[i,j]) \\},\n",
    "$$\n",
    "\n",
    "donde $x_i$ corresponde a un punto siguiendo una distribución equiespaciada o de Chebyshev e $I_k[i,j]$ denota el valor del pixel $(i,j)$ del $k$-ésimo frame. Su labor en esta pregunta es interpolar los datos de $S_{i,j}$ y así construir los pixeles que se desean agregar entre cada par de frames.\n",
    "\n",
    "1. Implemente la función _interpolate_\\__frames (frames, dst_\\__fps, seconds, interpolator)_. Esta función recibe como parámetros:\n",
    "    * La matriz de _frames_: Video original a interpolar.\n",
    "    * La cantidad original de *fps*.\n",
    "    * La cantidad de _fps_ deseados (mayor a los _fps_ originales).\n",
    "    * La cantidad de segundos que tendrá el video.\n",
    "    * Un string _interpolator_, cuyos valores posibles son:\n",
    "        * \"spline-cubica\": Spline cúbica. Estudie y seleccione un tipo de condición de borde adecuado para el problema, justificando su elección.\n",
    "        * \"spline-lineal\": Spline lineal.\n",
    "        * \"lagrange\": Interpolación polinomial mediante el método Interpolación de Lagrange.\n",
    "        * \"baricentrica\": Interpolación Baricéntrica [2].\n",
    "    * Un string 'points_type', cuyos valores posibles son:\n",
    "        * \"equi\": Para usar una distribución equiespaciada de puntos en el eje de las abscisas.\n",
    "        * \"cheb\": Los x_i (o eje de las abscisas) son los puntos de Chebyshev.\n",
    "\n",
    "    En caso de utilizar código ajeno, ya sean librerías, notebooks del curso u otro, recuerde referenciar apropiadamente.<br/><br/>\n",
    "\n",
    "2. Mediante la función implementada anteriormente, aumentaremos los *framerates* de los videos disponibles. Para esto:\n",
    "    * Tomando como base el _video_\\__30fps.mp4_, genere un video de 60 fps.\n",
    "    * Tomando como base el _video_\\__15fps.mp4_, genere un video de 30 fps.\n",
    "    * Tomando como base el _video_\\__5fps.mp4_, genere un video de 15 fps.\n",
    "    * Tomando como base el _video_\\__5fps.mp4_, genere un video de 60 fps.\n",
    "\n",
    "    Para esto, utilize los 4 interpoladores generados y las distribuciones de puntos especificadas. Mida los tiempos de cómputos de cada método, con cada distribución de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chebyshev_points(xmin,xmax,n):\n",
    "    ns = np.arange(1,n+1)\n",
    "    x = np.cos((2*ns-1)*np.pi/(2*n))\n",
    "    y = np.sin((2*ns-1)*np.pi/(2*n))\n",
    "    return (xmin+xmax)/2 + (xmax-xmin)*x/2\n",
    "\n",
    "def matrix_to_video(frames, old_fps, new_fps, width, height, interpolator, points_type):\n",
    "    name = \"video_\"+str(old_fps)+\"_to_\"+str(new_fps)+\"fps_\"+interpolator+\"_\"+points_type+\".mp4\"\n",
    "    out = cv2.VideoWriter(name, cv2.VideoWriter_fourcc('m','p','4','v'), new_fps, (width,height))\n",
    "    \n",
    "    for i in range(frames.shape[2]):\n",
    "        frame = np.uint8(frames[:,:,i])\n",
    "        out.write(np.dstack([frame, frame, frame]))\n",
    "    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "frames: array of frames (height x width x total_frames)\n",
    "old_fps: Number of fps of the original video\n",
    "new_fps: fps of output matrix \n",
    "seconds: seconds of video \n",
    "interpolator: Interpolator type\n",
    "points_type: Points distribution to use\n",
    "\n",
    "return: dst_frames (array of frames (height x width x dst_fps*seconds))\n",
    "'''\n",
    "\n",
    "def interpolate_frames(frames, old_fps, new_fps, seconds, interpolator, points_type):            \n",
    "    \n",
    "    if(new_fps > old_fps):\n",
    "        start_time = time() \n",
    "        mult = new_fps/old_fps\n",
    "        height = frames.shape[0]\n",
    "        width = frames.shape[1]\n",
    "        dst_frames = np.zeros((height, width, round(new_fps)*seconds), dtype=np.uint8)\n",
    "        \n",
    "        if(points_type == \"equi\"):\n",
    "            x = np.arange(0, frames.shape[2], 1)\n",
    "            xs = np.linspace(0, frames.shape[2]-1, num=round(new_fps)*seconds)\n",
    "            \n",
    "        elif(points_type == \"cheb\"):\n",
    "            x = Chebyshev_points(old_fps, 1, old_fps*seconds)\n",
    "            xs = Chebyshev_points(old_fps, 1, new_fps*seconds)\n",
    "            \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                ys = frames[i, j] \n",
    "\n",
    "                if(interpolator == \"spline-cubica\"): \n",
    "                    S = scp.CubicSpline(x, ys)\n",
    "\n",
    "                elif(interpolator == \"spline-lineal\"):\n",
    "                    S = scp.UnivariateSpline(x, ys)\n",
    "\n",
    "                elif(interpolator == \"lagrange\"):\n",
    "                    S = scp.lagrange(x, ys)\n",
    "\n",
    "                elif(interpolator == \"baricentrica\"):\n",
    "                    S = scp.BarycentricInterpolator(x, ys)\n",
    "\n",
    "                else:\n",
    "                    break  \n",
    "\n",
    "                dst_frames[i][j] = S(xs)\n",
    "\n",
    "        fps = int(dst_frames.shape[2]/seconds)\n",
    "        matrix_to_video(dst_frames, old_fps, fps, width, height, interpolator, points_type)\n",
    "        end_time = time() \n",
    "        exe_time = end_time - start_time\n",
    "        print(\"Video \" + str(old_fps) + \"-\" + str(new_fps) + \"fps (\" + interpolator + \"-\" + points_type + \"): \" + str(exe_time) +\" segs.\")\n",
    "            \n",
    "    return dst_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el manejo del video en el *notebook*, se les facilita la función `video_to_matrix` que les permitirá abrir un video y transformarlo a una estructura de datos de *numpy*. El resultado será una *array* de dimensión $\\text{height}\\times\\text{width}\\times\\text{Total de frames}$, donde *height* corresponde a la altura (en pixeles) del video y *width* al ancho del video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Carga de video a matriz de [height, width, fps*seconds], dejando en escala de grises cada frame, \n",
    "reduciendo su dimensionalidad.\n",
    "\n",
    "Input:\n",
    "    src_name: nombre (o path) de video de origen\n",
    "    seconds: cantidad de tiempo en segundos a considerar del video de origen.\n",
    "\n",
    "Output: \n",
    "    frames: matriz de shape [height, width, fps*seconds], la cual contiene los frames del video original\n",
    "    number_fps: frames por segundo del video original\n",
    "'''\n",
    "def video_to_matrix(src_name, seconds):\n",
    "    # Se lee el video\n",
    "    stream = cv2.VideoCapture(src_name)\n",
    "    \n",
    "    # Dimension del video y fps\n",
    "    height = round(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = round(stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    number_fps = stream.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    frames = np.zeros((height, width, round(number_fps)*seconds), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(round(number_fps)*seconds):\n",
    "        # Leer el video hasta que no hayan más datos\n",
    "        (grabbed, frame) = stream.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "            \n",
    "        # Leer el frame y cambiarlo a escala de grises\n",
    "        frame = cv2.resize(frame, (width, height)) \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames[:,:,i] = frame\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, el siguiente código sirve para visualizar un video dentro del mismo *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('\\\n",
    "<div align=\"middle\">\\\n",
    "<video width=\"80%\" controls>\\\n",
    "      <source src=\"./{0}\" type=\"video/mp4\">\\\n",
    "</video></div>'.format('video_60fps.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generación de los nuevos vídeos \n",
    "El siguiente bloque genera automáticamente los vídeos que ya van adjuntos. \n",
    "\n",
    "<strong> Nota: No es necesario ejecutar este bloque. Se dejó para mostrar como se generaron los nuevos vídeos. Su ejecución podría sustituir los vídeos generados y utilizados para el posterior análisis.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos = [\"spline-cubica\", \"spline-lineal\", \"baricentrica\"]    \n",
    "#tipos = [\"lagrange\"]\n",
    "\n",
    "for tipo in tipos:\n",
    "    \n",
    "    #5 a 15 fps\n",
    "    frames = video_to_matrix('video_5fps.mp4', 5)\n",
    "    interpolate_frames(frames, 5, 15, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 5, 15, 5, tipo, \"cheb\")\n",
    "    \n",
    "    #5 a 60 fps\n",
    "    frames = video_to_matrix('video_5fps.mp4', 5)\n",
    "    interpolate_frames(frames, 5, 60, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 5, 60, 5, tipo, \"cheb\")\n",
    "    \n",
    "    #15 a 30 fps\n",
    "    frames = video_to_matrix('video_15fps.mp4', 5)\n",
    "    interpolate_frames(frames, 15, 30, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 15, 30, 5, tipo, \"cheb\")\n",
    "    \n",
    "    #30 a 60 fps\n",
    "    frames = video_to_matrix('video_30fps.mp4', 5)\n",
    "    interpolate_frames(frames, 30, 60, 5, tipo, \"equi\")\n",
    "    interpolate_frames(frames, 30, 60, 5, tipo, \"cheb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiempos obtenidos para cada video\n",
    "   \n",
    "   En la siguiente tabla se muestran los tiempos que tardó cada interpolador para convertir cada video, dependiendo si se escogieron puntos equispaciados o por Chebyshev.\n",
    "\n",
    "| Interpolador | 5-15 fps (equi) | 5-15 fps (cheb) | 5-60 fps (equi) | 5-60 fps (cheb) | 15-30 fps (equi) | 15-30 fps (cheb) | 30-60 fps (equi) | 30-60 fps (cheb) |\n",
    "|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| Spline-Cúbica | 32.9 s| 29.7 s | 35.6 s | 32.2 s | 34.2 s | 30.1 s | 37.8 s | 35.0 s |\n",
    "| Spline-Lineal  | 33.8 s| 31.7 s | 37.2 s | 34.8 s | 86.4 s | 78.6 s | 166.3 s | 155.4 s |\n",
    "| Baricéntrica  | 53.5 s| 50.5 s | 64.6 s | 61.6 s | 153.4 s | 136.8 s | 348.1 s | 320.4 s |\n",
    "| Lagrange  | 500+ s| 500+ s | 500+ s | 500+ s | 500+ s | 500+ s | 500+ s | 500+ s |\n",
    "\n",
    "   Cabe destacar que no se obtuvieron resultados utilizando Lagrange. Al experimentar solo se pudo generar 2 videos de 5 a 15 fps con ambos tipos de puntos y cada uno demoró 1 hora aproximadamente, por lo que, se ignoraron para el análisis.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 (15 puntos). Visualización del interpolador y del error, a través del tiempo\n",
    "\n",
    "1. Utilizando el *widget* adjunto, visualice los resultados generados por los interpoladores, su error y comente al respecto. ¿Qué método le parece que tiene un mejor desempeño?\n",
    "\n",
    "**Nota**: usted debe modificar el *widget* en las secciones necesarias para que lea correctamente los videos generados por usted, acorde a los parámetros que se pueden variar. Puede modificar secciones del *widget* para que se adapte a sus códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5180481220e74ca78daf0a1ccf8ae1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='method', options=('spline-cubica', 'spline-lineal', 'lagrange', 'b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widget to plot the interpolation function\n",
    "def plot_interpolation(method, points_dist, i, j, fps_increase_type):\n",
    "    \n",
    "    # Elegimos el video a trabajar\n",
    "    if fps_increase_type == \"5->15\":\n",
    "        frames = video_to_matrix('video_15fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_5_to_15fps_' + method + \"_\" + points_dist + \".mp4\" \n",
    "        \n",
    "    elif fps_increase_type == \"5->60\":\n",
    "        frames = video_to_matrix('video_60fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_5_to_60fps_' + method + \"_\" + points_dist + \".mp4\"\n",
    "        \n",
    "    elif fps_increase_type == \"15->30\":\n",
    "        frames = video_to_matrix('video_30fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_15_to_30fps_' + method + \"_\" + points_dist + \".mp4\"\n",
    "        \n",
    "    else:\n",
    "        frames = video_to_matrix('video_60fps.mp4', 5)\n",
    "        interpolated_video_name = 'video_30_to_60fps_' + method + \"_\" + points_dist + \".mp4\"\n",
    "        \n",
    "    # Un punto por frame\n",
    "    x = np.arange(0, frames.shape[2], 1)\n",
    "    \n",
    "    # Obtención de la matriz de los videos con mayor framerate\n",
    "    interp_frames = video_to_matrix(interpolated_video_name, 5)\n",
    "    plt.figure(figsize=(15, 14))\n",
    "    \n",
    "    # Grafico del interpolador y los pixeles reales\n",
    "    plt.subplot(211)\n",
    "    plt.plot(x, interp_frames[i,j,:], 'rx-', label='Video interpolados')\n",
    "    plt.plot(x, frames[i,j,:], 'bd', label='Video esperado')\n",
    "    plt.ylim([0, 256])\n",
    "    plt.title('Comparación entre los pixeles interpolados y los deseados')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Valor pixel')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Grafico del error\n",
    "    plt.subplot(212)\n",
    "    error_matrix = frames - interp_frames\n",
    "    plt.plot(x, error_matrix[i,j,:], 'sk-', label='Error de interpolación')\n",
    "    mean_error = np.zeros(error_matrix.shape[2])\n",
    "    sigma = mean_error.copy()\n",
    "    for k in range(error_matrix.shape[2]):\n",
    "        mean_error[k] = error_matrix[:,:,k].mean()\n",
    "        sigma[k] = error_matrix[:,:,k].std()\n",
    "    plt.plot(x, mean_error, '.-', label='Error medio de interpolación')\n",
    "    plt.plot(x, mean_error + sigma, label='Error medio + desviación estándar')\n",
    "    plt.plot(x, mean_error - sigma, label='Error medio - desviación estándar')\n",
    "    plt.title('Error de interpolación')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Error')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    plot_interpolation, \n",
    "    method=[\"spline-cubica\",\"spline-lineal\",\"lagrange\",\"baricentrica\"],\n",
    "    points_dist=[\"equi\",\"cheb\"],\n",
    "    j=(0, 511),\n",
    "    i=(0, 269),\n",
    "    fps_increase_type=[\"5->60\", \"5->15\", \"15->30\", \"30->60\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de interactuar con los resultados obtenidos por los interpoladores se pueden destacar los siguientes puntos:\n",
    "\n",
    "- Hay mejores resultados, según los errores de interpolación, cuando se utilizan videos con mayores fps. Esto se debe a que existe una mayor cantidad de frames para construir los polinómios, por lo que el interpolador tiene más valores para determinar. A medida que el vídeo inicial tiene menos fps, aparecen más errores. También aparecen más errores cuando se desea aumentar bruscamente los fps, como en el caso de pasar de 5 a 15 fps o de 5 a 60 fps.\n",
    "    \n",
    "- Para un mismo video generado se puede notar que ciertos pixeles tienden a mostrar más errores de interpolación que otros. Una razón de esto se debe a la ubicación del pixel; si este se encuentra en una zona en donde no hay mucho movimiento (como el fondo), la interpolación presenta menos errores, pero, en el caso que se encuentre, por ejemplo, en el centro, entonces la interpolación tiende a tener más errores, lo que se puede observar desviación estándar del error. \n",
    "\n",
    "- Observando las interpolaciones y errores es posible notar que el método de Spline Cúbica es quien realiza una interpolación más precisa, según los pixeles que corresponden. Al cambiar a Spline Lineal se aprecia una buena interpolación igualmente, pero su precisión tiende a variar levemente y en ciertos casos aumenta levemente la cantidad de errores. Por último, la Baricéntrica es la que menos precisión tiene y mayor cantidad de errores presenta. Cabe destacar que depende del caso, es decir, cuando se analiza una conversión de 30-60 fps, todos los métodos presentan buenas interpolaciones; sin embargo, cuando la conversión es más brusca (5-15 fps o 5-60 fps) es más fácil encontrar las diferencias, donde la baricéntrica en algunos casos realiza interpolaciones totalmente incorrectas, lo que se puede apreciar en el vídeo generado.\n",
    "\n",
    "- En adición al punto anterior, los resultados se afinan dependiendo la distribución de puntos. En general, utilizando la distribución de Chebyshev se logran mejores interpolaciones, lo que se argumenta con la disminución de errores encontrados por frame para cada método y en los tiempos de ejecución respecto a una distribución equidistante. \n",
    "\n",
    "Por tanto, los métodos tienen mejor desempeño cuando se utiliza una distribución de Chebyshev para los puntos. Por otra parte, la Spline-Cúbica es la más eficiente, seguida por la Spline-Lineal que logra resultados muy similares, pero para mayores fps tiende a demorarse considerablemente más que el primer método. Por último, el peor desempeño lo tiene el método Baricéntrico debido a que para transformaciones más brucas presenta una alta cantidad de errores, sobretodo si se utilizan puntos equidistante, donde se generan vídeos donde la imágen se queda congelada. Esta conclusión es sin considerar el método de Lagrange, ya que, debido a sus tiempos de ejecución no se lograron obtener vídeos; no sería justo considerarlo el peor método, pues no se sabe la calidad de las interpolaciones que realiza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 (25 puntos). Comparación de Videos\n",
    "\n",
    "1. Utilizando los videos generados en la pregunta anterior, compare visualmente los videos generados con su versión de \"origen\" (video original al que se le agregaron nuevos *frames*) y con la versión \"esperada\" del video; por ejemplo, para la interpolación de 15fps a 30fps, el video de origen sería _video_\\__15fps.mp4_, y el video esperado _video_\\__30fps.mp4_. Comente al respecto. ¿Se realiza correctamente la interpolación? ¿Qué es lo que está haciendo visualmente la interpolación en los videos?\n",
    "\n",
    "    Para ayudar a la visualización de los videos, puede hacer uso de la función _concat_\\__2_\\__videos (src_\\__name, dst_\\__name, seconds)_, la cual permite concatenar o \"unir\" dos videos con el mismo framerate para realizar una comparativa en un nuevo video generado.\n",
    "\n",
    "    _NOTA: Debe hacer un preprocesamiento sobre el video de origen para compararlo con la interpolación, pues la función solo permite unir 2 videos de igual framerate. Una solución simple es repetir cada frame la cantidad necesaria para completar el framerate deseado_ <br/><br/>\n",
    "\n",
    "2. Comente respecto a los tiempos de cómputo obtenidos. ¿Existe alguna correlación entre la calidad del video generado y los tiempos de cómputo?\n",
    "\n",
    "3. Comente respecto al efecto de la distribución de puntos. ¿Genera alguna diferencia la distribución de puntos equiespaciada respecto a los puntos de Chebyshev?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "src_name: name/path of first video\n",
    "dst_name: name/path of second video\n",
    "seconds : seconds of video to consider.\n",
    "\n",
    "returns: None\n",
    "'''\n",
    "\n",
    "def concat_2_videos(src_name, dst_name, seconds):\n",
    "    stream = cv2.VideoCapture(src_name)\n",
    "    src_frames = video_to_matrix(src_name, seconds)\n",
    "    print(\"FPS VIDEO \"+src_name+\": \",int(src_frames.shape[2]/seconds))\n",
    "    \n",
    "    stream_2 = cv2.VideoCapture(dst_name)  \n",
    "    dst_frames = video_to_matrix(dst_name, seconds)\n",
    "    print(\"FPS VIDEO \"+dst_name+\": \",int(dst_frames.shape[2]/seconds))\n",
    "\n",
    "    # Close original videos\n",
    "    stream.release()\n",
    "    stream_2.release()\n",
    "    \n",
    "    # Repetición de frames del vídeo de origen para coincidir con el vídeo esperado\n",
    "    mult = int(dst_frames.shape[2]/seconds)/int(src_frames.shape[2]/seconds)\n",
    "    src_frames = np.repeat(src_frames[:, :], mult, axis=2)\n",
    "    \n",
    "    if dst_frames.shape[2] != src_frames.shape[2]:\n",
    "        print(\"No es posible concatenar dos videos de distinto fps\")\n",
    "        return\n",
    "    \n",
    "    fps = int(dst_frames.shape[2]/seconds)\n",
    "    \n",
    "    #concatenate both videos\n",
    "    conc_frames = np.concatenate((src_frames, dst_frames), axis=1)\n",
    "    \n",
    "    height = conc_frames.shape[0]\n",
    "    width = conc_frames.shape[1]\n",
    "    \n",
    "    #saving comparison on a new video\n",
    "    out = cv2.VideoWriter(\"comparison_\"+src_name+\"_vs_\"+dst_name,cv2.VideoWriter_fourcc('m','p','4','v'), fps, (width,height))\n",
    "   \n",
    "    for i in range(conc_frames.shape[2]):\n",
    "        frame = np.uint8(conc_frames[:,:,i])\n",
    "        out.write(np.dstack([frame, frame, frame]))\n",
    "    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS VIDEO video_5fps.mp4:  5\n",
      "FPS VIDEO video_5_to_60fps_spline-cubica_cheb.mp4:  60\n"
     ]
    }
   ],
   "source": [
    "concat_2_videos(\"video_5fps.mp4\", \"video_5_to_60fps_spline-cubica_cheb.mp4\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de concatenar los vídeos y compararlos se observa lo siguiente:\n",
    "- 1. Las interpolaciones se realizan correctamente en la mayoría de los casos, aunque se pueden encontrar ciertos detalles. Generalemente los mejores resultados son obtenidos con Splines Cúbicas o Lineales, donde la primera tiende a reducir la cantidad de píxeles incorrectos (puntos blancos en las imágenes). Cuando se utiliza la interpolación baricéntrica, existen casos que no hay una buena interpolación y la imagen se queda congelada; esto ocurre generalmente cuando se hacen transformaciones bruscas y se utiliza una distribución de puntos equidistante. Por otra parte, lo que hace la interpolación es generar nuevos frames (píxeles) que se ponen entremedio de dos ya existentes. El nuevo frame generado es una aproximación de lo que sería la imagen entre dos frames; en otras palabras, se crean nuevos pixeles en base a los originales y se rellena el video con nuevos frames, mejorando así, la fluidez de los movimientos de este.\n",
    "\n",
    "- 2. Los mejores resultados son obtenidos en menores tiempos de cómputos. La razón de esto depende del método; utilizar splines genera mayor precisión con menor tiempo de cómputo, a diferencia de utilizar una interpolación Baricéntrica o de Lagrange. \n",
    "\n",
    "\n",
    "Las Splines Cúbicas mejoran la apariencia de las curvas generadas por Splines lineales, pues, no solo calza los valores de los pixeles, sino, mejora la suavidad y las concavidades de cada segmento interpolado entre los pixeles. \n",
    "\n",
    "- 3. Es posible notar que para todos los casos, una distribución de puntos de Chebyshev hace que la interpolación sea más rápida que al ser equispaciado. La razón de esto se debe a que Chebyshev se utiliza para minimizar el problema del fenómeno de Runge, pues garantiza que el error máximo disminuye cuando crece el grado del polinomio [1], a diferencia de utilizar nodos equidistantes. Asimísmo, al utilizar Splines se obtienen mejores resultados porque se incrementa el número de partes del polinómio que se usan para construirla, en vez de incrementar su grado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 4 (10 puntos): Conclusión\n",
    "\n",
    "Considerando todo el trabajo anterior, concluya al respecto.\n",
    "\n",
    "1. _¿En palabras simples, qué es lo que realiza el interpolador entre cada par de *frames*?. **Hint: Un análisis frame a frame puede ayudar a responder esto.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>R:</strong> Genera una nueva imagen que podría representar lo que ocurre entre ambos frames (o instantes de tiempo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. _¿De qué manera se pueden mejorar los métodos estudiados para aumentar el framerate de un video?. **Hint: ¿Es adecuado considerar el conjunto de pixeles como independientes entre sí?**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>R:</strong> Al considerar los pixeles independientes entre si significa volver a computar repetitivamente las mimas funciones en la interpolación. Si se pudiera de alguna forma \"predecir\" o \"pre-calcular\" la variación de los valores de los pixeles, entonces se podría reutilizar las sumas en las funciones o simplemente ignorarlas. Por ejemplo, en un vídeo con fondo estático se podría ignorar la interpolación en esos puntos o se podría priorizar la interpolación a zonas que presenten más flujo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "[1] Stock footage provided by Videvo, downloaded from https://www.videvo.net\n",
    "\n",
    "[2] Barycentric Lagrange Interpolation, https://people.maths.ox.ac.uk/trefethen/barycentric.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea3_borrador.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/sgallard/tareasCC/blob/master/tarea3/Tarea3_borrador.ipynb",
     "timestamp": 1558739969669
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
